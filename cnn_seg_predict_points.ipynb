{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bd11b-adb7-44d3-a1a9-137a83606ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, Point\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.enums import Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import shapely.wkt as wkt\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils\n",
    "from tqdm import tqdm\n",
    "from skimage.measure import label, regionprops\n",
    "import os\n",
    "import dask\n",
    "import time\n",
    "import gc\n",
    "import re\n",
    "from rioxarray.exceptions import NoDataInBounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f21d8-4da6-493f-8aef-c6deed579977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "dask.config.set({\"distributed.nanny.environ.MALLOC_TRIM_THRESHOLD_\": 0})\n",
    "dask.config.set(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85d291-0187-49a8-8933-6b50f0dad9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "\n",
    "def trim_memory() -> int:\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)\n",
    "\n",
    "os.environ[\"MALLOC_TRIM_THRESHOLD_\"] = str(dask.config.get(\"distributed.nanny.environ.MALLOC_TRIM_THRESHOLD_\"))\n",
    "\n",
    "print(os.environ[\"MALLOC_TRIM_THRESHOLD_\"])\n",
    "\n",
    "#os.environ[\"MALLOC_TRIM_THRESHOLD_\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00fa48-5d5e-4a18-a5f5-a5f4c338d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray as riox\n",
    "from xrspatial import convolution, focal, hillshade\n",
    "from skimage.transform import resize\n",
    "from dask.distributed import LocalCluster, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6c4e7-b288-4279-826d-39975e5db58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=8, threads_per_worker=2, processes=True)\n",
    "client = Client(cluster)\n",
    "client.amm.start()\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f525e70-71fa-4741-985d-96ff430aeb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to normalize all data in range 0-1\n",
    "def normalize_fn(image, image_suffix, stats_dict):\n",
    "    if image_suffix in stats_dict.keys():\n",
    "        min_tmp = stats_dict[image_suffix]['min']\n",
    "        max_tmp = stats_dict[image_suffix]['max']\n",
    "    else:\n",
    "        # normalize to individual image if min/max stats not specified in dictionary\n",
    "        min_tmp = np.min(image)\n",
    "        max_tmp = np.max(image)\n",
    "    return (image - min_tmp) / (max_tmp - min_tmp)\n",
    "\n",
    "def calc_tpi(dtm, inner_r, outer_r, values=True):\n",
    "    cellsize_x, cellsize_y = convolution.calc_cellsize(dtm)\n",
    "    kernel = convolution.annulus_kernel(cellsize_x, cellsize_y, outer_r, inner_r)\n",
    "    tpi = dtm - focal.apply(dtm, kernel)\n",
    "    if values:\n",
    "        return tpi.values\n",
    "    else:\n",
    "        return tpi\n",
    "\n",
    "def calc_ndvi(ms, values=True):\n",
    "    ndvi = (ms.sel(band=4).astype('float') - ms.sel(band=3).astype('float'))\\\n",
    "            / (ms.sel(band=4).astype('float') + ms.sel(band=3).astype('float'))\n",
    "    if values:\n",
    "        return ndvi.values\n",
    "    else:\n",
    "        return ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f35503-1a23-405a-b4db-0ccd6bf58e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from operator import mul\n",
    "\n",
    "try:\n",
    "    reduce = reduce\n",
    "except NameError:\n",
    "    from functools import reduce # py3k\n",
    "\n",
    "Info = namedtuple('Info', 'start height')\n",
    "\n",
    "def max_size(mat, value=0):\n",
    "    \"\"\"Find height, width of the largest rectangle containing all `value`'s.\n",
    "    For each row solve \"Largest Rectangle in a Histrogram\" problem [1]:\n",
    "    [1]: http://blog.csdn.net/arbuckle/archive/2006/05/06/710988.aspx\n",
    "    \"\"\"\n",
    "    it = iter(mat)\n",
    "    hist = [(el==value) for el in next(it, [])]\n",
    "    max_size = max_rectangle_size(hist)\n",
    "    for row in it:\n",
    "        hist = [(1+h) if el == value else 0 for h, el in zip(hist, row)]\n",
    "        max_size = max(max_size, max_rectangle_size(hist), key=area)\n",
    "    return max_size\n",
    "\n",
    "def max_rectangle_size(histogram):\n",
    "    \"\"\"Find height, width of the largest rectangle that fits entirely under\n",
    "    the histogram.\n",
    "    >>> f = max_rectangle_size\n",
    "    >>> f([5,3,1])\n",
    "    (3, 2)\n",
    "    >>> f([1,3,5])\n",
    "    (3, 2)\n",
    "    >>> f([3,1,5])\n",
    "    (5, 1)\n",
    "    >>> f([4,8,3,2,0])\n",
    "    (3, 3)\n",
    "    >>> f([4,8,3,1,1,0])\n",
    "    (3, 3)\n",
    "    >>> f([1,2,1])\n",
    "    (1, 3)\n",
    "    Algorithm is \"Linear search using a stack of incomplete subproblems\" [1].\n",
    "    [1]: http://blog.csdn.net/arbuckle/archive/2006/05/06/710988.aspx\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    top = lambda: stack[-1]\n",
    "    max_size = (0, 0) # height, width of the largest rectangle\n",
    "    pos = 0 # current position in the histogram\n",
    "    for pos, height in enumerate(histogram):\n",
    "        start = pos # position where rectangle starts\n",
    "        while True:\n",
    "            if not stack or height > top().height:\n",
    "                stack.append(Info(start, height)) # push\n",
    "            elif stack and height < top().height:\n",
    "                max_size = max(max_size, (top().height, (pos - top().start)),\n",
    "                               key=area)\n",
    "                start, _ = stack.pop()\n",
    "                continue\n",
    "            break # height == top().height goes here\n",
    "\n",
    "    pos += 1\n",
    "    for start, height in stack:\n",
    "        max_size = max(max_size, (height, (pos - start)), key=area)\n",
    "\n",
    "    return max_size\n",
    "\n",
    "def area(size):\n",
    "    return reduce(mul, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63c3c8-46cd-4c0b-adda-d02fd9219f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outDIR = './cnn_pred_results/'\n",
    "if not os.path.exists(outDIR):\n",
    "    os.mkdir(outDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c6224-dea0-47b1-80eb-45b6b6a4df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['burrow']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda' #'cuda'# 'cpu'# \n",
    "model_fnl = 'deeplabplus'\n",
    "res_fnl = 5\n",
    "inputs_fnl = ['rgb', 'tpi', 'ndvi'] \n",
    "preprocess = True\n",
    "prob_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df3061-2ae6-445d-8a2f-2224a273dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#past_subset = None\n",
    "past_subset = ['22W', '22E', 'CN']\n",
    "\n",
    "img_f_dict = {\n",
    "    '5W': {\n",
    "        'group_1': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_5W_RGB/CPER_202109_5W_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_5W_MS/CPER_202109_5W_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_5W_RGB/CPER_202109_5W_RGB_dsm.tif'\n",
    "        }\n",
    "    },\n",
    "    '29-30': {\n",
    "        'group_1': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_29_30_RGB/CPER_202109_29_30_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_29_30_MS/CPER_202109_29_30_North_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_29_30_RGB/CPER_202109_29_30_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_2': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_29_30_RGB/CPER_202109_29_30_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_29_30_MS/CPER_202109_29_30_South_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_29_30_RGB/CPER_202109_29_30_RGB_DSM.tif'\n",
    "        }\n",
    "    },\n",
    "    '22W': {\n",
    "        'group_1': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight1_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight1_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight1_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_2': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_RGB_DSM.tif'\n",
    "        }\n",
    "    },\n",
    "    '22E': {\n",
    "        'group_1': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight1_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight1_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight1_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_2': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_3': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight3_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight2_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_22EW/CPER_202109_22EW_Flight3_RGB_DSM.tif'\n",
    "        }\n",
    "    },\n",
    "    'CN': {\n",
    "        'group_1': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_CN_RGB/Orthos/CPER_CN_Flight2_202109_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_CN_MS/CPER_202109_CN_Flight2_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_CN_RGB/DSMs/CPER_CN_Flight2_202109_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_2': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_CN_RGB/Orthos/CPER_CN_Flight3_202109_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_CN_MS/CPER_202109_CN_Flight2_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_CN_RGB/DSMs/CPER_CN_Flight3_202109_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_3': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_CN_RGB/Orthos/CPER_CN_Flight4_202109_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_CN_MS/CPER_202109_CN_Flight3_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_CN_RGB/DSMs/CPER_CN_Flight4_202109_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_4': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_CN_RGB/Orthos/CPER_CN_Flight5_202109_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_CN_MS/CPER_202109_CN_Flight3_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_CN_RGB/DSMs/CPER_CN_Flight5_202109_RGB_DSM.tif'\n",
    "        },\n",
    "        'group_5': {\n",
    "            'rgb': '/mnt/d/202109/outputs/202109_CN_RGB/Orthos/CPER_CN_Flight5_202109_RGB_ortho.tif',\n",
    "            'ms': '/mnt/d/202109/outputs/202109_CN_MS/CPER_202109_CN_Flight4_MS_ortho.tif',\n",
    "            'dsm': '/mnt/d/202109/outputs/202109_CN_RGB/DSMs/CPER_CN_Flight5_202109_RGB_DSM.tif'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if past_subset is not None:\n",
    "    img_f_dict_tmp = img_f_dict.copy()\n",
    "    img_f_dict = {}\n",
    "    for k in img_f_dict_tmp:\n",
    "         if k in past_subset:\n",
    "                img_f_dict[k] = img_f_dict_tmp[k]\n",
    "\n",
    "cper_f = '/mnt/c/Users/TBGPEA-Sean/Desktop/Pdogs_UAS/cper_pdog_pastures_2017_clip.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f0f45-d52c-48f8-853b-7404abd75ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_buff_size = 25\n",
    "full_tile_size = 100\n",
    "tile_size = 256\n",
    "buff_size = 64\n",
    "chunk_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cb02e-10b7-4fd3-bc0d-10832aff67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "if res_fnl == 2:\n",
    "    best_model = torch.load('./cnn_results_' + model_fnl + '_' + str(res_fnl) + 'cm/best_model_' + '_'.join(inputs_fnl) + '.pth')\n",
    "else:\n",
    "    best_model = torch.load('./cnn_results_' + model_fnl + '_' + str(res_fnl) + 'cm/best_model_' + '_'.join(inputs_fnl) + '_' + str(res_fnl) + 'cm.pth')\n",
    "\n",
    "if DEVICE == 'cpu':\n",
    "    best_model = best_model.cpu()\n",
    "best_model.eval()\n",
    "\n",
    "# load the image stats from the training data\n",
    "df_image_stats = pd.read_csv('./_utils/image_stats_2cm.csv').set_index('stat')\n",
    "\n",
    "# convert image stats dictionary to dataframe\n",
    "image_stats = {i: {'min': df_image_stats.loc['min', i],\n",
    "                   'max': df_image_stats.loc['max', i]} for i in df_image_stats.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e43d7a-2fa6-4585-a712-7144e6a41d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasture = '22E'\n",
    "#group = 'group_3'\n",
    "fig, ax = plt.subplots()\n",
    "cper_gdf = gpd.read_file(cper_f)\n",
    "hfig = display(cper_gdf.plot(ax=ax, color='none', edgecolor='black'), display_id=True, clear=True)\n",
    "\n",
    "for pasture in tqdm(img_f_dict):\n",
    "    print('\\n\\n----------\\nPasture: ' + pasture)\n",
    "    for group in tqdm(img_f_dict[pasture]):\n",
    "        print('---\\nGroup: ' + group)\n",
    "\n",
    "        # load in approapriate image data\n",
    "        rgb_f = img_f_dict[pasture][group]['rgb']\n",
    "        ms_f = img_f_dict[pasture][group]['ms']\n",
    "        dsm_f = img_f_dict[pasture][group]['dsm']\n",
    "\n",
    "        # get the bounding box of the pasture\n",
    "        past_bbox = cper_gdf[cper_gdf['Past_Name_'] == pasture].buffer(\n",
    "            np.ceil(buff_size * res_fnl * 0.01)).bounds.apply(lambda x: int(x))\n",
    "\n",
    "        # open image data and mask and rename where appropriate\n",
    "        rgb_xr = riox.open_rasterio(rgb_f, chunks={'y': chunk_size, \n",
    "                                                   'x': chunk_size,\n",
    "                                                   'band': 1}).sel(band=slice(0, 3))\n",
    "        rgb_xr = rgb_xr.where(rgb_xr != 255)\n",
    "        ms_xr = riox.open_rasterio(ms_f, chunks={'y': chunk_size,\n",
    "                                                 'x': chunk_size,\n",
    "                                                 'band': 1}).sel(band=[4, 3])\n",
    "        ms_xr = ms_xr.where(ms_xr != 65535)\n",
    "        dsm_xr = riox.open_rasterio(dsm_f, chunks={'y': chunk_size,\n",
    "                                                   'x': chunk_size}).squeeze().drop('band')\n",
    "        dsm_xr.name = 'DSM'\n",
    "        dsm_xr = dsm_xr.where(dsm_xr > 0)\n",
    "\n",
    "        # subset image data to pasture boundaries\n",
    "        rgb_xr = rgb_xr.sel(y=slice(past_bbox['maxy'], past_bbox['miny']), \n",
    "                            x=slice(past_bbox['minx'], past_bbox['maxx']))\n",
    "\n",
    "        ms_xr = ms_xr.sel(y=slice(past_bbox['maxy'], past_bbox['miny']), \n",
    "                            x=slice(past_bbox['minx'], past_bbox['maxx']))\n",
    "\n",
    "        dsm_xr = dsm_xr.sel(y=slice(past_bbox['maxy'], past_bbox['miny']), \n",
    "                            x=slice(past_bbox['minx'], past_bbox['maxx']))\n",
    "\n",
    "        # get count of any null data remaining in imagery within pasture boundaries\n",
    "        ms_ct_null = ms_xr.isel(band=0).isnull().sum().compute()\n",
    "        dsm_ct_null = dsm_xr.isnull().sum().compute()\n",
    "\n",
    "        # if more than 1% of the multispectral data is null\n",
    "        # get the largest rectangle (to nearest 10 m) of non-null multispectral data\n",
    "        if (ms_ct_null/(ms_xr.shape[1]*ms_xr.shape[2])) > 0.01:\n",
    "            # coarsen imagery to approximately 10 m\n",
    "            ms_1m_coarse_val = int(10.0/ms_xr.rio.resolution()[0])\n",
    "            ms_1m_res = ms_1m_coarse_val * ms_xr.rio.resolution()[0]\n",
    "            ms_1m = ms_xr.isel(band=1).notnull().astype('int').coarsen(x=ms_1m_coarse_val,\n",
    "                                                                      y=ms_1m_coarse_val, boundary='trim').max().compute()\n",
    "\n",
    "            # get the size of the largest rectangle with no null values\n",
    "            cln_rect = max_size(ms_1m.values, value=1)\n",
    "            cln_rect\n",
    "\n",
    "            # get the number of rows and columns to iterate through to find lower-left coords of non-null rectangle\n",
    "            x_chk_n = (ms_1m.x.max() - (ms_1m.x.min() + ((cln_rect[1] - 1) * ms_1m_res))) / ms_1m_res + 1\n",
    "            y_chk_n = (ms_1m.y.max() - (ms_1m.y.min() + ((cln_rect[0] - 1) * ms_1m_res))) / ms_1m_res + 1\n",
    "\n",
    "            # iterate through the rows and columns and save all starting coordinates with non-null rectangles\n",
    "            x_cln_list = []\n",
    "            y_cln_list = []\n",
    "            for x in tqdm(np.arange(ms_1m.x.min(), ms_1m.x.min() + x_chk_n * ms_1m_res, ms_1m_res)):\n",
    "                for y in np.arange(ms_1m.y.min(), ms_1m.y.min() + y_chk_n * ms_1m_res, ms_1m_res):\n",
    "                    chk_null = (ms_1m.sel(x=slice(x, x + cln_rect[1] * ms_1m_res-1),\n",
    "                                         y=slice(y + cln_rect[0] * ms_1m_res-1, y)) == 1).all()\n",
    "                    if chk_null:\n",
    "                        x_cln_list.append(x)\n",
    "                        y_cln_list.append(y)\n",
    "\n",
    "\n",
    "            # save the minimum starting coordinates\n",
    "            coords_cln = pd.Series({'x': x_cln_list[np.argmin(y_cln_list)], 'y': np.min(y_cln_list)})\n",
    "            coords_cln\n",
    "\n",
    "            # update the extent of the multispectral image and rechunk for NDVI calc later\n",
    "            ms_xr = ms_xr.sel(y=slice(coords_cln['y'] + cln_rect[0]*ms_1m_res, coords_cln['y']), \n",
    "                              x=slice(coords_cln['x'], coords_cln['x'] + cln_rect[1]*ms_1m_res)).chunk({'y': 500, 'x': 500, 'band': -1})\n",
    "\n",
    "        # if more than 1% of the RGB DSM data is null\n",
    "        # get the largest rectangle (to nearest 10 m) of non-null RGB DSM data\n",
    "        if (dsm_ct_null/(dsm_xr.shape[0]*dsm_xr.shape[1])) > 0.01:\n",
    "            # coarsen imagery to approximately 10 m\n",
    "            dsm_1m_coarse_val = int(10.0/dsm_xr.rio.resolution()[0])\n",
    "            dsm_1m_res = dsm_1m_coarse_val * dsm_xr.rio.resolution()[0]\n",
    "            dsm_1m = dsm_xr.notnull().astype('int').coarsen(x=dsm_1m_coarse_val,\n",
    "                                                            y=dsm_1m_coarse_val, boundary='trim').max().compute()\n",
    "\n",
    "            # get the size of the largest rectangle with no null values\n",
    "            cln_rect = max_size(dsm_1m.values, value=1)\n",
    "            cln_rect\n",
    "\n",
    "            # get the number of rows and columns to iterate through to find lower-left coords of non-null rectangle\n",
    "            x_chk_n = (dsm_1m.x.max() - (dsm_1m.x.min() + ((cln_rect[1] - 1) * dsm_1m_res))) / dsm_1m_res + 1\n",
    "            y_chk_n = (dsm_1m.y.max() - (dsm_1m.y.min() + ((cln_rect[0] - 1) * dsm_1m_res))) / dsm_1m_res + 1\n",
    "\n",
    "            # iterate through the rows and columns and save all starting coordinates with non-null rectangles\n",
    "            x_cln_list = []\n",
    "            y_cln_list = []\n",
    "            for x in tqdm(np.arange(dsm_1m.x.min(), dsm_1m.x.min() + x_chk_n * dsm_1m_res, dsm_1m_res)):\n",
    "                for y in np.arange(dsm_1m.y.min(), dsm_1m.y.min() + y_chk_n * dsm_1m_res, dsm_1m_res):\n",
    "                    chk_null = (dsm_1m.sel(x=slice(x, x + cln_rect[1] * dsm_1m_res-1),\n",
    "                                         y=slice(y + cln_rect[0] * dsm_1m_res-1, y)) == 1).all()\n",
    "                    if chk_null:\n",
    "                        x_cln_list.append(x)\n",
    "                        y_cln_list.append(y)\n",
    "\n",
    "\n",
    "            # save the minimum starting coordinates\n",
    "            coords_cln = pd.Series({'x': x_cln_list[np.argmin(y_cln_list)], 'y': np.min(y_cln_list)})\n",
    "            coords_cln\n",
    "\n",
    "            # update the extent of the RGB and DSM images\n",
    "            rgb_xr = rgb_xr.sel(y=slice(coords_cln['y'] + cln_rect[0]*dsm_1m_res, coords_cln['y']), \n",
    "                              x=slice(coords_cln['x'], coords_cln['x'] + cln_rect[1]*dsm_1m_res))\n",
    "            dsm_xr = dsm_xr.sel(y=slice(coords_cln['y'] + cln_rect[0]*dsm_1m_res, coords_cln['y']), \n",
    "                              x=slice(coords_cln['x'], coords_cln['x'] + cln_rect[1]*dsm_1m_res))\n",
    "\n",
    "        del ms_ct_null, dsm_ct_null    \n",
    "        client.run(gc.collect)\n",
    "        client.run(trim_memory)\n",
    "        # get the minimum bounding box of all non-null data\n",
    "        past_bbox['minx'] = max(rgb_xr.x.min().values, ms_xr.x.min().values, dsm_xr.x.min().values, past_bbox['minx'])\n",
    "        past_bbox['miny'] = max(rgb_xr.y.min().values, ms_xr.y.min().values, dsm_xr.y.min().values, past_bbox['miny'])\n",
    "        past_bbox['maxx'] = min(rgb_xr.x.max().values, ms_xr.x.max().values, dsm_xr.x.max().values, past_bbox['maxx'])\n",
    "        past_bbox['maxy'] = min(rgb_xr.y.max().values, ms_xr.y.max().values, dsm_xr.y.max().values, past_bbox['maxy'])\n",
    "        \n",
    "        total_bounds = {'xmin': past_bbox['minx'],\n",
    "                        'xmax': past_bbox['maxx'],\n",
    "                        'ymin': past_bbox['miny'],\n",
    "                        'ymax': past_bbox['maxy']}\n",
    "        \n",
    "        n_row_tiles = int(np.ceil((total_bounds['ymax'] - total_bounds['ymin'])/full_tile_size))\n",
    "        n_col_tiles = int(np.ceil((total_bounds['xmax'] - total_bounds['xmin'])/full_tile_size))\n",
    "\n",
    "        \n",
    "        # subset image data to the updated pasture subset boundaries\n",
    "        rgb_xr = rgb_xr.sel(y=slice(past_bbox['maxy'], past_bbox['miny']), \n",
    "                            x=slice(past_bbox['minx'], past_bbox['maxx']))\n",
    "\n",
    "        ms_xr = ms_xr.sel(y=slice(past_bbox['maxy'], past_bbox['miny']), \n",
    "                            x=slice(past_bbox['minx'], past_bbox['maxx']))\n",
    "\n",
    "        dsm_xr = dsm_xr.sel(y=slice(past_bbox['maxy'], past_bbox['miny']), \n",
    "                            x=slice(past_bbox['minx'], past_bbox['maxx']))\n",
    "        \n",
    "        # plot the current pasture and bounding box of the analsis area in the output preview\n",
    "        cper_gdf[cper_gdf['Past_Name_'] == pasture].plot(ax=ax)\n",
    "        gpd.GeoSeries(Polygon([(past_bbox['minx'], past_bbox['miny']),\n",
    "                 (past_bbox['minx'], past_bbox['maxy']),\n",
    "                 (past_bbox['maxx'], past_bbox['maxy']),\n",
    "                 (past_bbox['maxx'], past_bbox['miny'])])).plot(ax=ax, edgecolor='red', color='none')\n",
    "        fig.canvas.draw()\n",
    "        hfig.update(fig)\n",
    "\n",
    "        outSHP = os.path.join(outDIR, 'burrow_pts_pred_' + '_'.join([pasture, group]) + '_' + '_'.join(inputs_fnl + [str(res_fnl)]) + 'cm.shp')\n",
    "        if os.path.exists(outSHP):\n",
    "            gdf_out = gpd.read_file(outSHP)\n",
    "            r_ct_pred = len(gdf_out)\n",
    "            rc_completed = gdf_out.apply(lambda x: '_'.join([str(x.tile_row), str(x.tile_col)]), axis=1).unique()\n",
    "        elif os.path.exists(re.sub('.shp', '.csv', outSHP)):\n",
    "            gdf_out = pd.read_csv(re.sub('.shp', '.csv', outSHP))\n",
    "            r_ct_pred = len(gdf_out)\n",
    "            rc_completed = gdf_out.apply(lambda x: '_'.join([str(x.tile_row), str(x.tile_col)]), axis=1).unique()\n",
    "        else:\n",
    "            r_ct_pred = 0\n",
    "            gdf_out = gpd.GeoDataFrame()\n",
    "            rc_completed = []\n",
    "\n",
    "        try:\n",
    "            client.restart(timeout=9)\n",
    "            time.sleep(10)\n",
    "        except TimeoutError:\n",
    "            client.shutdown()\n",
    "            client.close()\n",
    "            cluster = LocalCluster(n_workers=8, threads_per_worker=2, processes=True)\n",
    "            client = Client(cluster)\n",
    "            client.amm.start()\n",
    "            \n",
    "        for full_r in range(n_row_tiles):\n",
    "            print('running row: ' + str(full_r) + ' of ' + str(n_row_tiles))\n",
    "            for full_c in tqdm(range(n_col_tiles)):\n",
    "                if len(client.cluster.workers) < 8:\n",
    "                    client.shutdown()\n",
    "                    client.close()\n",
    "                    cluster = LocalCluster(n_workers=8, threads_per_worker=2, processes=True)\n",
    "                    client = Client(cluster)\n",
    "                    client.amm.start()\n",
    "                if '_'.join([str(full_r), str(full_c)]) in rc_completed:\n",
    "                    #print('skipping row/column combination, already in shapefile!')\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        t0=time.time()\n",
    "                        ll = [full_c * full_tile_size + total_bounds['xmin'],\n",
    "                              full_r * full_tile_size + total_bounds['ymin']]\n",
    "                        ul = [ll[0], ll[1] + full_tile_size]\n",
    "                        ur = [x + full_tile_size for x in ll]\n",
    "                        lr = [ll[0] + full_tile_size, ll[1]]\n",
    "\n",
    "                        image_dict = {}\n",
    "                        newsize_r = int(round((ul[1] - ll[1]) / (res_fnl * 0.01), 0))\n",
    "                        newsize_c = int(round((lr[0] - ll[0]) / (res_fnl * 0.01), 0))\n",
    "                        if 'rgb' in inputs_fnl:\n",
    "                            #print('getting RGB')\n",
    "                            t1=time.time()\n",
    "                            image_dict['rgb'] = rgb_xr.sel(band=slice(1, 3),\n",
    "                                                           x=slice(ll[0], lr[0]),\n",
    "                                                           y=slice(ul[1], ll[1])).rio.reproject(\n",
    "                                rgb_xr.rio.crs,\n",
    "                                shape=(newsize_r, newsize_c),\n",
    "                                resampling=Resampling.bilinear).values\n",
    "                            #rgb_xr.close()\n",
    "                            t2=time.time()\n",
    "                            #print('... completed in', round(t2 - t1, 1), 'secs')\n",
    "                        if 'dsm' in inputs_fnl:\n",
    "                            t1 = time.time()\n",
    "                            #print('getting DSM')\n",
    "                            image_dict['dsm'] = dsm_xr.sel(x=slice(ll[0], lr[0]),\n",
    "                                                                y=slice(ul[1], ll[1])).squeeze().rio.reproject(\n",
    "                                dsm_xr.rio.crs,\n",
    "                                shape=(newsize_r, newsize_c),\n",
    "                                resampling=Resampling.bilinear).values\n",
    "                            #dsm_xr.close()\n",
    "                            t2=time.time()\n",
    "                            #print('... completed in', round(t2 - t1, 1), 'secs')\n",
    "                        if 'tpi' in inputs_fnl: \n",
    "                            t1 = time.time()\n",
    "                            #print('computing TPI')\n",
    "                            # prepare an annulus kernel with a ring at a distance from 5-10 cells away from focal point\n",
    "                            outer_radius = \"0.75m\"\n",
    "                            inner_radius = \"0.25m\"\n",
    "                            image_dict['tpi'] = calc_tpi(dsm_xr.sel(x=slice(ll[0], lr[0]),\n",
    "                                                                    y=slice(ul[1], ll[1])).squeeze().rio.reproject(\n",
    "                                dsm_xr.rio.crs,\n",
    "                                shape=(newsize_r, newsize_c),\n",
    "                                resampling=Resampling.bilinear).chunk({'x': chunk_size,\n",
    "                                                                       'y': chunk_size}), inner_r=inner_radius, outer_r=outer_radius, values=True)\n",
    "                            #dsm_xr.close()\n",
    "                            t2=time.time()\n",
    "                            #print('... completed in', round(t2 - t1, 1), 'secs')\n",
    "                        if 'ndvi' in inputs_fnl:\n",
    "                            t1 = time.time()\n",
    "                            #print('computing NDVI')\n",
    "                            image_dict['ndvi'] = calc_ndvi(ms_xr.sel(x=slice(ll[0], lr[0]),\n",
    "                                                                     y=slice(ul[1], ll[1])).rio.reproject(\n",
    "                                ms_xr.rio.crs,\n",
    "                                shape=(newsize_r, newsize_c),\n",
    "                                resampling=Resampling.bilinear), values=True)\n",
    "                            #ms_xr.close()\n",
    "                            t2=time.time()\n",
    "                            #print('... completed in', round(t2 - t1, 1), 'secs')\n",
    "\n",
    "                        if 'rgb' in image_dict:\n",
    "                            tshape = image_dict['rgb'].shape[1:]\n",
    "                        else:\n",
    "                            tshape = image_dict[inputs_fnl[0]].shape\n",
    "\n",
    "                        n_row_chunks = int(np.ceil(tshape[0]/tile_size))\n",
    "                        n_col_chunks = int(np.ceil(tshape[1]/tile_size))\n",
    "\n",
    "                        pr_mask = np.empty(tshape)\n",
    "                        t1 = time.time()\n",
    "                        #print('predicting binary burrow image')\n",
    "                        for r in range(n_row_chunks):\n",
    "                            if (r + 1) * tile_size > tshape[0]:\n",
    "                                r_min = tshape[0] - tile_size\n",
    "                                r_max = tshape[0]\n",
    "                                r_max_comp = tshape[0]\n",
    "                            elif (r + 1) * tile_size + buff_size > tshape[0]:\n",
    "                                r_min = r * tile_size\n",
    "                                r_max = (r + 1) * tile_size\n",
    "                                r_max_comp = r_max\n",
    "                            else:\n",
    "                                r_min = r * tile_size\n",
    "                                r_max = (r + 1) * tile_size\n",
    "                                r_max_comp = r_max + buff_size\n",
    "                            for c in range(n_col_chunks):\n",
    "                                image_sub_dict = {}\n",
    "                                if (c + 1) * tile_size > tshape[1]:\n",
    "                                    c_min = tshape[1] - tile_size\n",
    "                                    c_max = tshape[1]\n",
    "                                    c_max_comp = tshape[1]\n",
    "                                elif (c + 1) * tile_size + buff_size > tshape[1]:\n",
    "                                    c_min = c * tile_size\n",
    "                                    c_max = (c + 1) * tile_size\n",
    "                                    c_max_comp = c_max\n",
    "                                else:\n",
    "                                    c_min = c * tile_size\n",
    "                                    c_max = (c + 1) * tile_size\n",
    "                                    c_max_comp = c_max + buff_size\n",
    "                                for k in image_dict:\n",
    "                                    if k == 'rgb':\n",
    "                                        image_sub_dict[k] = image_dict[k][:,\n",
    "                                                                          slice(max(0, r_min-buff_size), r_max_comp),\n",
    "                                                                          slice(max(0, c_min-buff_size), c_max_comp)].astype('float32')\n",
    "                                    else:\n",
    "                                        image_sub_dict[k] = image_dict[k][slice(max(0, r_min-buff_size), r_max_comp),\n",
    "                                                                          slice(max(0, c_min-buff_size), c_max_comp)].astype('float32')\n",
    "                                    if len(image_sub_dict[k].shape) == 2:\n",
    "                                        image_sub_dict[k] = np.expand_dims(image_sub_dict[k], 0)\n",
    "                                if preprocess:\n",
    "                                    for i in image_sub_dict:\n",
    "                                        image_sub_dict[i] = normalize_fn(image_sub_dict[i], i, image_stats)\n",
    "                                image_list = [image_sub_dict[i] for i in inputs_fnl]\n",
    "                                image_out = np.concatenate(image_list, axis=0)\n",
    "                                x_tensor = torch.from_numpy(image_out).to(DEVICE).unsqueeze(0)\n",
    "                                if type(best_model) == nn.DataParallel:\n",
    "                                    pred_tmp = best_model.module.predict(x_tensor).cpu().detach().numpy().squeeze() >= prob_thresh\n",
    "                                    buff_r_min = buff_size * int(r_min-buff_size > 0)\n",
    "                                    buff_r_max = buff_size * int(r_max+buff_size < tshape[0])\n",
    "                                    buff_c_min = buff_size * int(c_min-buff_size > 0)\n",
    "                                    buff_c_max = buff_size * int(c_max+buff_size < tshape[1])\n",
    "                                    if pred_tmp.shape[1] > tile_size:\n",
    "                                        pr_mask[r_min:r_max, c_min:c_max] = pred_tmp[buff_r_min:pred_tmp.shape[0]-buff_r_max,\n",
    "                                                                                     buff_c_min:pred_tmp.shape[1]-buff_c_max]\n",
    "                                    else:\n",
    "                                        pr_mask[r_min:r_max, c_min:c_max] = pred_tmp\n",
    "                                else:\n",
    "                                    pred_tmp = best_model.predict(x_tensor).cpu().detach().numpy().squeeze() >= prob_thresh\n",
    "                                    buff_r_min = buff_size * int(r_min-buff_size > 0)\n",
    "                                    buff_r_max = buff_size * int(r_max+buff_size < tshape[0])\n",
    "                                    buff_c_min = buff_size * int(c_min-buff_size > 0)\n",
    "                                    buff_c_max = buff_size * int(c_max+buff_size < tshape[1])\n",
    "                                    if pred_tmp.shape[1] > tile_size:\n",
    "                                        pr_mask[r_min:r_max, c_min:c_max] = pred_tmp[buff_r_min:pred_tmp.shape[0]-buff_r_max,\n",
    "                                                                                     buff_c_min:pred_tmp.shape[1]-buff_c_max]\n",
    "                                    else:\n",
    "                                        pr_mask[r_min:r_max, c_min:c_max] = pred_tmp\n",
    "                        t2=time.time()\n",
    "                        #print('... completed in', round(t2 - t1, 1), 'secs')\n",
    "                        t1 = time.time()\n",
    "                        #print('getting burrow locations')\n",
    "                        pr_labels = label(pr_mask)\n",
    "                        pr_regions = regionprops(pr_labels)\n",
    "                        if len(pr_regions) == 0:\n",
    "                            #print('no burrow locations found!')\n",
    "                            gdf_tmp = gpd.GeoDataFrame(data=pd.DataFrame({'area': ''}, index=[r_ct_pred]))\n",
    "                            gdf_tmp['tile_row'] = full_r\n",
    "                            gdf_tmp['tile_col'] =  full_c\n",
    "                            gdf_tmp['tile_size'] = full_tile_size\n",
    "                            gdf_out = pd.concat([gdf_out, gdf_tmp])\n",
    "                            del gdf_tmp\n",
    "                            r_ct_pred += 1\n",
    "                        else:\n",
    "                            for r in pr_regions:\n",
    "                                if r.area*(res_fnl/100)**2 > 0.05:\n",
    "                                    gdf_tmp = gpd.GeoDataFrame(data=pd.DataFrame({'area': r.area}, index=[r_ct_pred]), geometry=[Point([ll[0] + r.centroid[1]*(res_fnl*0.01),\n",
    "                                                                                                                                        ul[1] - r.centroid[0]*(res_fnl*0.01)])], crs='EPSG:32613')\n",
    "                                    gdf_tmp['tile_row'] = full_r\n",
    "                                    gdf_tmp['tile_col'] =  full_c\n",
    "                                    gdf_tmp['tile_size'] = full_tile_size\n",
    "                                    gdf_out = pd.concat([gdf_out, gdf_tmp])\n",
    "                                    if type(gdf_out) is pd.core.frame.DataFrame:\n",
    "                                        gdf_out = gpd.GeoDataFrame(gdf_out, geometry = gdf_out['geometry'])\n",
    "                                    del gdf_tmp\n",
    "                                    r_ct_pred += 1\n",
    "                        t2=time.time()\n",
    "                        #print('... completed in', round(t2 - t1, 1), 'secs')\n",
    "                        if type(gdf_out) is pd.core.frame.DataFrame:\n",
    "                            gdf_out.to_csv(re.sub('.shp', '.csv', outSHP), index=False)\n",
    "                        else:\n",
    "                            gdf_out.to_file(outSHP)\n",
    "                        del pr_mask, pred_tmp, pr_labels, pr_regions, image_dict, image_sub_dict, image_list, image_out\n",
    "                        client.run(gc.collect)\n",
    "                        client.run(trim_memory)\n",
    "                        if full_c % 2 == 0:\n",
    "                            try:\n",
    "                                client.restart(timeout=9)\n",
    "                                time.sleep(10)\n",
    "                            except TimeoutError:\n",
    "                                client.shutdown()\n",
    "                                client.close()\n",
    "                                cluster = LocalCluster(n_workers=8, threads_per_worker=2, processes=True)\n",
    "                                client = Client(cluster)\n",
    "                                client.amm.start()\n",
    "                            \n",
    "                        #client.restart()\n",
    "                    except NoDataInBounds:\n",
    "                        continue\n",
    "                        #print('No data in bounds. Skipping row/column.')\n",
    "            if not '_'.join([str(full_r), str(full_c)]) in rc_completed:\n",
    "                try:\n",
    "                    client.restart(timeout=9)\n",
    "                    time.sleep(10)\n",
    "                except TimeoutError:\n",
    "                    client.shutdown()\n",
    "                    client.close()\n",
    "                    cluster = LocalCluster(n_workers=8, threads_per_worker=2, processes=True)\n",
    "                    client = Client(cluster)\n",
    "                    client.amm.start()\n",
    "        print('Pasture-group finished!')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
