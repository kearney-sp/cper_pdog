{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805b4878-fed6-4dea-af0b-bbf21a903c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "#os.environ['LD_LIBRARY_PATH']= '$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6450ba-f2a8-407b-b4b3-a48d87b00571",
   "metadata": {},
   "source": [
    "### Prep lists of input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0d91b2-cef1-4c19-b08c-bdc1f682d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from random import sample, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab307572-c831-44de-a43a-d7d872a397d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_list = ['resnet34']\n",
    "avail_suffix = ['rgb', 'tpi', 'shade', 'ndvi', 'dsm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40650c2d-2675-4431-a3d3-a7124ee8ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "os.chdir('/project/cper_neon_aop/cper_pdog_uas')\n",
    "\n",
    "# set directories for training data and labels\n",
    "DATA_FOLDER = './cnn_train_images/{}_{}.tif'\n",
    "LABEL_FOLDER = './cnn_train_labels/{}_labels.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964c07d0-dd79-486d-9a45-26cf7b84d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csvs with training information\n",
    "df_tiles = pd.read_csv('train_tiles/train_bboxes_all_assigned.csv')\n",
    "df_polys = pd.read_csv('train_polys/train_polys_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92bddfb-90ba-468b-a358-9ee021cb0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all ids to be used\n",
    "label_files = glob(LABEL_FOLDER.replace('{}', '*'))\n",
    "all_ids = [re.sub('_labels.tif', '', os.path.basename(f)) for f in label_files]\n",
    "all_tiles = list(set(['_'.join(y.split('_')[2:]) for y in all_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09eb2d92-e56e-431a-8b11-2d599336ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training and test data and get paths to files\n",
    "all_files = glob(DATA_FOLDER.replace('{}', '*'))\n",
    "all_train_tiles = [x for x in df_tiles.apply(lambda x: '_'.join([x.Pasture, x.Tile]) if x.Train == 1 else '', axis=1) if x != '' and x in all_tiles]\n",
    "test_tiles = list(set(all_tiles) - set(all_train_tiles))\n",
    "\n",
    "all_train_ids = [x for x in all_ids if '_'.join(x.split('_')[-3:]) in all_train_tiles]\n",
    "test_ids = list(set(all_ids) - set(all_train_ids))\n",
    "\n",
    "seed(321)\n",
    "valid_ids = sample(all_train_ids, int(np.ceil(len(all_train_ids)*0.3)))\n",
    "train_ids = list(set(all_train_ids) - set(valid_ids))\n",
    "\n",
    "train_files = [f for f in all_files if '_'.join(os.path.basename(f).split('_')[:-1]) in train_ids]\n",
    "valid_files = [f for f in all_files if '_'.join(os.path.basename(f).split('_')[:-1]) in valid_ids]\n",
    "test_files = [f for f in all_files if '_'.join(os.path.basename(f).split('_')[:-1]) in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c06f11-1701-4cc8-81be-d7c26c7a0ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_ids = df_tiles[(df_tiles['trainer'] != 'Nick') &\n",
    "                    (df_tiles['Digitize'] == 1)].apply(lambda x: '_'.join([x.Pasture, x.Tile]), axis=1)\n",
    "#all_tiles#\n",
    "[x for x in all_tiles if x not in tile_ids.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ace3e5-8ab0-4e18-8ea6-b3d00c690c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in tile_ids.to_list() if x not in all_tiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180703c2-6582-4b02-8ef2-78e9de7db704",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "Writing helper class for data extraction, tranformation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100b2c6e-9f49-42d8-9346-4000ffc9c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616adccf-9bcb-421d-9bb6-04d16c48815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \"\"\"Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        ids (list): list of unique ids for all images\n",
    "        images_path (str): path to data images\n",
    "        masks_path (str): path to label masks\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    CLASSES = ['other', 'burrow']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            ids,\n",
    "            suffix_list,\n",
    "            images_path,\n",
    "            masks_path, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "            suffix_dict = {\n",
    "        'rgb': {'channels': 3,\n",
    "                'dtype': 'uint8'},\n",
    "        'tpi': {'channels': 1,\n",
    "                'dtype': 'float32'},\n",
    "        'dsm': {'channels': 1,\n",
    "                'dtype': 'float32'},\n",
    "        'shade': {'channels': 1,\n",
    "                  'dtype': 'float32'},\n",
    "        'ndvi': {'channels': 1,\n",
    "                  'dtype': 'float32'}\n",
    "    }\n",
    "    ):\n",
    "        # get IDs as attribute\n",
    "        self.ids = ids\n",
    "        \n",
    "        # get suffix info\n",
    "        self.suffix_dict = suffix_dict\n",
    "        \n",
    "        # get list of suffixes as attribute\n",
    "        self.suffix_list = suffix_list\n",
    "        \n",
    "        # List of files\n",
    "        self.images_fps = []\n",
    "        self.masks_fps = [masks_path.format(id) for id in ids]\n",
    "        for id in ids:\n",
    "            self.images_fps.append({s: images_path.format(id, s) for s in suffix_list})\n",
    "            \n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image_list = []\n",
    "        self.image_dict = {}\n",
    "        for s in self.suffix_list:\n",
    "            image_s = np.asarray(io.imread(self.images_fps[i][s]), dtype=self.suffix_dict[s]['dtype'])\n",
    "            if len(image_s.shape) == 2:\n",
    "                image_s = np.expand_dims(image_s, axis=-1)\n",
    "            image_s[np.isnan(image_s)] = 0\n",
    "            image_list.append(image_s)\n",
    "            self.image_dict[s] = image_s\n",
    "        if len(image_list) == 1:\n",
    "            image = image_list[0]\n",
    "        else:\n",
    "            image = np.concatenate(image_list, axis=-1)\n",
    "        mask = np.asarray(io.imread(self.masks_fps[i]), dtype='float32')\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1)#.astype('float32')\n",
    "        #print('fetched: ', self.ids[i])\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        else:\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1).astype('float32'))\n",
    "            mask = torch.from_numpy(mask.transpose(2, 0, 1).astype('float32'))\n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883c9ba-4e4c-4bd8-be2f-412a950d423b",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add831ba-9a5d-4a6b-813c-cfcbe917ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5eb644-3d27-40f3-b75f-e8517faf35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    win_size = 32 * random.randint(7, 10)\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "\n",
    "        #albu.ShiftScaleRotate(scale_limit=0.0, rotate_limit=45, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        #albu.PadIfNeeded(min_height=win_size, min_width=win_size, always_apply=True, border_mode=4),\n",
    "        albu.RandomCrop(height=win_size, width=win_size, always_apply=True),\n",
    "\n",
    "        #albu.GaussNoise(p=0.2, var_limit=1.0),\n",
    "        #albu.Perspective(p=0.5),\n",
    "\n",
    "        #albu.OneOf(\n",
    "        #    [\n",
    "        #        #albu.CLAHE(p=1), # required int8 images\n",
    "        #        albu.RandomBrightnessContrast(p=1),\n",
    "        #        #albu.RandomGamma(p=1),\n",
    "        #        #albu.HueSaturationValue(p=1),\n",
    "        #    ],\n",
    "        #    p=0.9,\n",
    "        #),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.Sharpen(p=1),\n",
    "                albu.Blur(blur_limit=(3, 7), p=1),\n",
    "                albu.MotionBlur(blur_limit=(3, 7), p=1),\n",
    "            ],\n",
    "            p=0.25,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(384, 480)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe86ab2-173c-4ae2-84e3-161213c60ce7",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03d0cbb-6436-4b1d-9ab7-ca856e3de540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils\n",
    "import torch.nn as nn\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3381ab39-295e-49e3-b70a-e1fdad7fe3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['burrow']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cuda'# 'cpu'# \n",
    "USE_PARALLEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504c232a-505a-4d9a-9b04-c422e12db46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "#list(itertools.combinations(avail_suffix, len(avail_suffix)))\n",
    "suffix_combinations = list()\n",
    "for n in range(1, len(avail_suffix) + 1):\n",
    "    suffix_combinations += list(itertools.combinations(avail_suffix, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cbaf71a-c873-4635-a5bf-ccc13762ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "outDIR = './cnn_results_fpn/'\n",
    "if not os.path.exists(outDIR):\n",
    "    os.mkdir(outDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a920a-5b90-45e2-8d2a-26ef7ddce7a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "['rgb']\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 56/56 [00:10<00:00,  5.32it/s, mccloss - 0.9278, iou_score - 0.03469, accuracy - 0.4911, precision - 0.03486, recall - 0.8762, fscore - 0.06557]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 33.48it/s, mccloss - 0.9515, iou_score - 0.02773, accuracy - 0.574, precision - 0.02794, recall - 0.9457, fscore - 0.05068] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.42it/s, mccloss - 0.8657, iou_score - 0.07181, accuracy - 0.7635, precision - 0.07224, recall - 0.9306, fscore - 0.1296] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 36.17it/s, mccloss - 0.9313, iou_score - 0.04236, accuracy - 0.7552, precision - 0.04265, recall - 0.9374, fscore - 0.07342]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.86it/s, mccloss - 0.8284, iou_score - 0.1157, accuracy - 0.8624, precision - 0.117, recall - 0.9484, fscore - 0.1978]   \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.79it/s, mccloss - 0.9207, iou_score - 0.0882, accuracy - 0.8285, precision - 0.1031, recall - 0.9291, fscore - 0.125]   \n",
      "Model saved!\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.52it/s, mccloss - 0.7792, iou_score - 0.1871, accuracy - 0.9248, precision - 0.1922, recall - 0.9311, fscore - 0.2966]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.08it/s, mccloss - 0.8982, iou_score - 0.129, accuracy - 0.902, precision - 0.1333, recall - 0.8829, fscore - 0.1738]   \n",
      "Model saved!\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.14it/s, mccloss - 0.7408, iou_score - 0.2337, accuracy - 0.9434, precision - 0.2443, recall - 0.8883, fscore - 0.3519]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.52it/s, mccloss - 0.8792, iou_score - 0.2433, accuracy - 0.8983, precision - 0.2709, recall - 0.9159, fscore - 0.2905] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.67it/s, mccloss - 0.7032, iou_score - 0.2596, accuracy - 0.9539, precision - 0.2752, recall - 0.8983, fscore - 0.385] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.03it/s, mccloss - 0.8618, iou_score - 0.3698, accuracy - 0.9543, precision - 0.4131, recall - 0.882, fscore - 0.4199] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.13it/s, mccloss - 0.6586, iou_score - 0.3028, accuracy - 0.9634, precision - 0.3287, recall - 0.8763, fscore - 0.4328]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 33.46it/s, mccloss - 0.8297, iou_score - 0.3144, accuracy - 0.9642, precision - 0.3485, recall - 0.8894, fscore - 0.3703]\n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.26it/s, mccloss - 0.6234, iou_score - 0.3278, accuracy - 0.9689, precision - 0.3544, recall - 0.8425, fscore - 0.4582]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.17it/s, mccloss - 0.8256, iou_score - 0.5055, accuracy - 0.9744, precision - 0.5872, recall - 0.8718, fscore - 0.556] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.24it/s, mccloss - 0.5921, iou_score - 0.3484, accuracy - 0.9728, precision - 0.389, recall - 0.8315, fscore - 0.4816] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.08it/s, mccloss - 0.842, iou_score - 0.3993, accuracy - 0.9527, precision - 0.4457, recall - 0.8789, fscore - 0.451]  \n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 10\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.43it/s, mccloss - 0.5701, iou_score - 0.3437, accuracy - 0.9719, precision - 0.3802, recall - 0.8498, fscore - 0.4756]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.94it/s, mccloss - 0.8198, iou_score - 0.3009, accuracy - 0.9522, precision - 0.3117, recall - 0.9, fscore - 0.3537]   \n",
      "No improvement in 2 epochs. Model not saved.\n",
      "\n",
      "Epoch: 11\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.98it/s, mccloss - 0.5394, iou_score - 0.3719, accuracy - 0.9766, precision - 0.4232, recall - 0.8397, fscore - 0.5065]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.05it/s, mccloss - 0.8122, iou_score - 0.5319, accuracy - 0.9762, precision - 0.6078, recall - 0.8617, fscore - 0.5825]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 12\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.61it/s, mccloss - 0.5137, iou_score - 0.3891, accuracy - 0.9793, precision - 0.4578, recall - 0.8152, fscore - 0.5263]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 31.14it/s, mccloss - 0.781, iou_score - 0.5607, accuracy - 0.985, precision - 0.6764, recall - 0.8379, fscore - 0.6096]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 13\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.07it/s, mccloss - 0.521, iou_score - 0.3738, accuracy - 0.9797, precision - 0.4442, recall - 0.7676, fscore - 0.5091] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 36.60it/s, mccloss - 0.7759, iou_score - 0.4337, accuracy - 0.9702, precision - 0.4775, recall - 0.8955, fscore - 0.4855]\n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 14\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.16it/s, mccloss - 0.4845, iou_score - 0.4053, accuracy - 0.9812, precision - 0.4871, recall - 0.8165, fscore - 0.5402]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 33.60it/s, mccloss - 0.7933, iou_score - 0.6207, accuracy - 0.9875, precision - 0.7371, recall - 0.8212, fscore - 0.6659]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 15\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.40it/s, mccloss - 0.4744, iou_score - 0.4122, accuracy - 0.9825, precision - 0.4947, recall - 0.8095, fscore - 0.5448]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.72it/s, mccloss - 0.7767, iou_score - 0.4824, accuracy - 0.9806, precision - 0.5523, recall - 0.8723, fscore - 0.5311]\n",
      "No improvement in 1 epochs. Model not saved.\n",
      "Decrease decoder learning rate by factor of 10\n",
      "\n",
      "Epoch: 16\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.31it/s, mccloss - 0.449, iou_score - 0.4332, accuracy - 0.9845, precision - 0.511, recall - 0.7996, fscore - 0.5696]  \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 36.06it/s, mccloss - 0.7775, iou_score - 0.6157, accuracy - 0.9885, precision - 0.761, recall - 0.825, fscore - 0.6593]  \n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 17\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.88it/s, mccloss - 0.4372, iou_score - 0.4535, accuracy - 0.986, precision - 0.545, recall - 0.7992, fscore - 0.5902]  \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.61it/s, mccloss - 0.7729, iou_score - 0.6128, accuracy - 0.9892, precision - 0.7487, recall - 0.8238, fscore - 0.6572]\n",
      "No improvement in 2 epochs. Model not saved.\n",
      "\n",
      "Epoch: 18\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.33it/s, mccloss - 0.4271, iou_score - 0.4676, accuracy - 0.9864, precision - 0.5601, recall - 0.786, fscore - 0.6022] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.81it/s, mccloss - 0.762, iou_score - 0.6209, accuracy - 0.9882, precision - 0.7258, recall - 0.8533, fscore - 0.6671] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 19\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.38it/s, mccloss - 0.418, iou_score - 0.4739, accuracy - 0.9871, precision - 0.5611, recall - 0.8004, fscore - 0.6073] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.01it/s, mccloss - 0.7574, iou_score - 0.5981, accuracy - 0.9884, precision - 0.7036, recall - 0.8505, fscore - 0.6452]\n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 20\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.63it/s, mccloss - 0.4151, iou_score - 0.4816, accuracy - 0.9878, precision - 0.5837, recall - 0.8018, fscore - 0.6161]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 32.66it/s, mccloss - 0.7594, iou_score - 0.6165, accuracy - 0.9891, precision - 0.7294, recall - 0.8508, fscore - 0.6632]\n",
      "No improvement in 2 epochs. Model not saved.\n",
      "\n",
      "Epoch: 21\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.59it/s, mccloss - 0.393, iou_score - 0.5098, accuracy - 0.989, precision - 0.6031, recall - 0.8397, fscore - 0.64]    \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.79it/s, mccloss - 0.7604, iou_score - 0.6377, accuracy - 0.9899, precision - 0.7769, recall - 0.8382, fscore - 0.6844]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 22\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.56it/s, mccloss - 0.4034, iou_score - 0.5031, accuracy - 0.9885, precision - 0.6003, recall - 0.7839, fscore - 0.6322]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.41it/s, mccloss - 0.7595, iou_score - 0.6438, accuracy - 0.9899, precision - 0.7716, recall - 0.845, fscore - 0.691]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 23\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.32it/s, mccloss - 0.4027, iou_score - 0.4928, accuracy - 0.988, precision - 0.5776, recall - 0.8254, fscore - 0.624]  \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.32it/s, mccloss - 0.7634, iou_score - 0.6337, accuracy - 0.9899, precision - 0.7722, recall - 0.8336, fscore - 0.6795]\n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 24\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.66it/s, mccloss - 0.3879, iou_score - 0.5153, accuracy - 0.9891, precision - 0.6162, recall - 0.797, fscore - 0.6448] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.46it/s, mccloss - 0.7619, iou_score - 0.6297, accuracy - 0.9903, precision - 0.7741, recall - 0.8269, fscore - 0.6763]\n",
      "No improvement in 2 epochs. Model not saved.\n",
      "\n",
      "Epoch: 25\n",
      "train: 100%|██████████| 56/56 [00:07<00:00,  7.96it/s, mccloss - 0.389, iou_score - 0.5138, accuracy - 0.9891, precision - 0.6082, recall - 0.8027, fscore - 0.6428] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 36.36it/s, mccloss - 0.7677, iou_score - 0.6444, accuracy - 0.99, precision - 0.7731, recall - 0.8212, fscore - 0.6902]  \n",
      "No improvement in 3 epochs. Model not saved.\n",
      "\n",
      "Epoch: 26\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.76it/s, mccloss - 0.3789, iou_score - 0.5258, accuracy - 0.9897, precision - 0.6192, recall - 0.8425, fscore - 0.656] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.13it/s, mccloss - 0.7634, iou_score - 0.6218, accuracy - 0.9902, precision - 0.758, recall - 0.8174, fscore - 0.6679] \n",
      "No improvement in 4 epochs. Model not saved.\n",
      "\n",
      "Epoch: 27\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  8.86it/s, mccloss - 0.3731, iou_score - 0.5339, accuracy - 0.9902, precision - 0.6197, recall - 0.8558, fscore - 0.6601]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.08it/s, mccloss - 0.7694, iou_score - 0.636, accuracy - 0.9905, precision - 0.7955, recall - 0.81, fscore - 0.6814]   \n",
      "No improvement in 5 epochs. Model not saved.\n",
      "More than 5 epochs without validation improvement while learning rate <= 1e-5 and training improvement < 0.05...ending training\n",
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "['tpi']\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 56/56 [00:05<00:00, 10.44it/s, mccloss - 0.8941, iou_score - 0.06565, accuracy - 0.6863, precision - 0.06641, recall - 0.8646, fscore - 0.1181] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.05it/s, mccloss - 0.9681, iou_score - 0.02087, accuracy - 0.4354, precision - 0.02092, recall - 0.9117, fscore - 0.03866]   \n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 56/56 [00:05<00:00, 10.22it/s, mccloss - 0.8235, iou_score - 0.1398, accuracy - 0.8674, precision - 0.1421, recall - 0.9127, fscore - 0.2323] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 37.03it/s, mccloss - 0.9052, iou_score - 0.0862, accuracy - 0.8921, precision - 0.08853, recall - 0.9334, fscore - 0.1277] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.09it/s, mccloss - 0.7694, iou_score - 0.2172, accuracy - 0.9252, precision - 0.2249, recall - 0.9306, fscore - 0.3337]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.22it/s, mccloss - 0.8695, iou_score - 0.4438, accuracy - 0.9611, precision - 0.5044, recall - 0.9071, fscore - 0.495]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|██████████| 56/56 [00:05<00:00, 10.17it/s, mccloss - 0.725, iou_score - 0.2613, accuracy - 0.9437, precision - 0.2752, recall - 0.9123, fscore - 0.3855] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 33.68it/s, mccloss - 0.8592, iou_score - 0.5219, accuracy - 0.9627, precision - 0.592, recall - 0.9103, fscore - 0.5747]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.96it/s, mccloss - 0.6866, iou_score - 0.2869, accuracy - 0.9502, precision - 0.3028, recall - 0.852, fscore - 0.4117] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 37.13it/s, mccloss - 0.8505, iou_score - 0.4864, accuracy - 0.9572, precision - 0.5638, recall - 0.9087, fscore - 0.5374]\n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.78it/s, mccloss - 0.64, iou_score - 0.3319, accuracy - 0.9623, precision - 0.3631, recall - 0.8769, fscore - 0.4628]  \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.42it/s, mccloss - 0.8128, iou_score - 0.5551, accuracy - 0.9819, precision - 0.6337, recall - 0.8862, fscore - 0.6089]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.74it/s, mccloss - 0.6164, iou_score - 0.328, accuracy - 0.9623, precision - 0.3589, recall - 0.8533, fscore - 0.4554] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.68it/s, mccloss - 0.7904, iou_score - 0.5552, accuracy - 0.9779, precision - 0.6205, recall - 0.9243, fscore - 0.6138] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|██████████| 56/56 [00:05<00:00, 10.16it/s, mccloss - 0.5673, iou_score - 0.3723, accuracy - 0.9706, precision - 0.4109, recall - 0.8894, fscore - 0.505] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.63it/s, mccloss - 0.7791, iou_score - 0.6476, accuracy - 0.9881, precision - 0.7441, recall - 0.8846, fscore - 0.6976]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.23it/s, mccloss - 0.5302, iou_score - 0.409, accuracy - 0.9759, precision - 0.4559, recall - 0.8846, fscore - 0.5399] \n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.45it/s, mccloss - 0.784, iou_score - 0.561, accuracy - 0.9758, precision - 0.6179, recall - 0.9311, fscore - 0.6199]   \n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 10\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.37it/s, mccloss - 0.5037, iou_score - 0.4211, accuracy - 0.9788, precision - 0.4849, recall - 0.8706, fscore - 0.5565]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 33.07it/s, mccloss - 0.7689, iou_score - 0.4833, accuracy - 0.9828, precision - 0.5296, recall - 0.8926, fscore - 0.536]  \n",
      "No improvement in 2 epochs. Model not saved.\n",
      "\n",
      "Epoch: 11\n",
      "train: 100%|██████████| 56/56 [00:05<00:00, 10.33it/s, mccloss - 0.4965, iou_score - 0.4232, accuracy - 0.9804, precision - 0.5092, recall - 0.7931, fscore - 0.5577]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 35.69it/s, mccloss - 0.7703, iou_score - 0.5265, accuracy - 0.9831, precision - 0.5967, recall - 0.8943, fscore - 0.5813]\n",
      "No improvement in 3 epochs. Model not saved.\n",
      "\n",
      "Epoch: 12\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.15it/s, mccloss - 0.474, iou_score - 0.4273, accuracy - 0.9804, precision - 0.5017, recall - 0.8319, fscore - 0.5639] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 36.67it/s, mccloss - 0.7457, iou_score - 0.5515, accuracy - 0.9822, precision - 0.6265, recall - 0.8965, fscore - 0.6058] \n",
      "No improvement in 4 epochs. Model not saved.\n",
      "\n",
      "Epoch: 13\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.90it/s, mccloss - 0.4577, iou_score - 0.4481, accuracy - 0.9836, precision - 0.5472, recall - 0.7939, fscore - 0.5795]\n",
      "valid: 100%|██████████| 144/144 [00:04<00:00, 34.31it/s, mccloss - 0.7468, iou_score - 0.671, accuracy - 0.9912, precision - 0.8007, recall - 0.8468, fscore - 0.7168]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 14\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.69it/s, mccloss - 0.4226, iou_score - 0.4736, accuracy - 0.9845, precision - 0.5547, recall - 0.8043, fscore - 0.607] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 37.18it/s, mccloss - 0.7284, iou_score - 0.6821, accuracy - 0.991, precision - 0.8014, recall - 0.8634, fscore - 0.7283]     \n",
      "Model saved!\n",
      "\n",
      "Epoch: 15\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.37it/s, mccloss - 0.4271, iou_score - 0.466, accuracy - 0.9852, precision - 0.5712, recall - 0.8022, fscore - 0.5994] \n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 37.16it/s, mccloss - 0.7438, iou_score - 0.677, accuracy - 0.9908, precision - 0.8069, recall - 0.8447, fscore - 0.7222] \n",
      "No improvement in 1 epochs. Model not saved.\n",
      "Decrease decoder learning rate by factor of 10\n",
      "\n",
      "Epoch: 16\n",
      "train: 100%|██████████| 56/56 [00:06<00:00,  9.31it/s, mccloss - 0.3886, iou_score - 0.5104, accuracy - 0.9875, precision - 0.5956, recall - 0.8394, fscore - 0.6389]\n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 37.41it/s, mccloss - 0.7317, iou_score - 0.6694, accuracy - 0.9912, precision - 0.7935, recall - 0.8539, fscore - 0.715] \n",
      "No improvement in 1 epochs. Model not saved.\n",
      "\n",
      "Epoch: 17\n",
      "train: 100%|██████████| 56/56 [00:05<00:00,  9.73it/s, mccloss - 0.3715, iou_score - 0.5326, accuracy - 0.9887, precision - 0.6304, recall - 0.8102, fscore - 0.6627]\n",
      "valid: 100%|██████████| 144/144 [00:03<00:00, 36.69it/s, mccloss - 0.7431, iou_score - 0.6922, accuracy - 0.9913, precision - 0.8439, recall - 0.8328, fscore - 0.7375]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 18\n",
      "train:  98%|█████████▊| 55/56 [00:05<00:00, 12.42it/s, mccloss - 0.3704, iou_score - 0.5298, accuracy - 0.9881, precision - 0.6221, recall - 0.8307, fscore - 0.6571]"
     ]
    }
   ],
   "source": [
    "for suffix_sub in suffix_combinations:\n",
    "    suffix_list = list(suffix_sub)\n",
    "    print('\\n\\n----------------------------------------------------------')\n",
    "    print(suffix_list)\n",
    "    if os.path.exists(outDIR + 'best_model_' + '_'.join(suffix_list) + '_validation.txt'):\n",
    "        print('skipping - already trained.')\n",
    "        continue\n",
    "    else:\n",
    "        train_dataset = Dataset(\n",
    "            train_ids,\n",
    "            suffix_list,\n",
    "            DATA_FOLDER,\n",
    "            LABEL_FOLDER,\n",
    "            augmentation=get_training_augmentation(),\n",
    "            #preprocessing=get_preprocessing(preprocessing_fn),\n",
    "            classes=CLASSES)\n",
    "\n",
    "        valid_dataset = Dataset(\n",
    "            valid_ids,\n",
    "            suffix_list,\n",
    "            DATA_FOLDER,\n",
    "            LABEL_FOLDER,\n",
    "            #augmentation=get_validation_augmentation(),\n",
    "            #preprocessing=get_preprocessing(preprocessing_fn),\n",
    "            classes=CLASSES)\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=6, shuffle=False,\n",
    "                                  drop_last=True, num_workers=6, pin_memory=False)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=6, pin_memory=False)\n",
    "\n",
    "        # create segmentation model with pretrained encoder\n",
    "        model = smp.FPN(\n",
    "            encoder_name=ENCODER, \n",
    "            encoder_weights=ENCODER_WEIGHTS, \n",
    "            classes=len(CLASSES), \n",
    "            activation=ACTIVATION,\n",
    "            in_channels=train_dataset[0][0].shape[0],\n",
    "        )\n",
    "        \n",
    "        if USE_PARALLEL:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "        # Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "        # IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "        loss = smp.losses.MCCLoss()\n",
    "        loss.__name__ = 'mccloss'\n",
    "        metrics = [\n",
    "            utils.metrics.IoU(threshold=0.5),\n",
    "            utils.metrics.Accuracy(threshold=0.5),\n",
    "            utils.metrics.Precision(threshold=0.5),\n",
    "            utils.metrics.Recall(threshold=0.5),\n",
    "            utils.metrics.Fscore(threshold=0.5)\n",
    "        ]\n",
    "\n",
    "        optimizer = torch.optim.Adam([ \n",
    "            dict(params=model.parameters(), lr=0.0001),\n",
    "        ])\n",
    "\n",
    "        # create epoch runners \n",
    "        # it is a simple loop of iterating over dataloader`s samples\n",
    "        train_epoch = utils.train.TrainEpoch(\n",
    "            model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            optimizer=optimizer,\n",
    "            device=DEVICE,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        valid_epoch = utils.train.ValidEpoch(\n",
    "            model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            device=DEVICE,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # train model for up to 60 epochs\n",
    "\n",
    "        max_score = 0\n",
    "        max_score_train = 0\n",
    "        no_improve = 0\n",
    "\n",
    "        for i in range(1, 61):\n",
    "\n",
    "            print('\\nEpoch: {}'.format(i))\n",
    "            train_logs = train_epoch.run(train_loader)\n",
    "            valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "            # do something (save model, change lr, etc.)\n",
    "            if max_score < valid_logs['fscore']:\n",
    "                max_score = valid_logs['fscore']\n",
    "                max_score_train = train_logs['fscore']\n",
    "                torch.save(model, outDIR + 'best_model_' + '_'.join(suffix_list) + '.pth')\n",
    "                valid_logs['best_epoch'] = i\n",
    "                best_valid_logs = valid_logs.copy()\n",
    "                print('Model saved!')\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                print('No improvement in ' + str(no_improve) + ' epochs. Model not saved.')\n",
    "\n",
    "            if i > 15:\n",
    "                if no_improve >= 5:\n",
    "                    if (train_logs['fscore'] - max_score_train) < 0.05:\n",
    "                        print('More than 5 epochs without validation improvement while learning rate <= 1e-5 and training improvement < 0.05...ending training')\n",
    "                        with open(outDIR + 'best_model_' + '_'.join(suffix_list) + '_validation.txt','w') as data: \n",
    "                            data.write(str(best_valid_logs))\n",
    "                        break\n",
    "                    elif (train_logs['fscore'] - max_score_train) < 0.10 and no_improve == 15:\n",
    "                        print('15 epochs without validation improvement while learning rate <= 1e-5...ending training')\n",
    "                        with open(outDIR + 'best_model_' + '_'.join(suffix_list) + '_validation.txt','w') as data: \n",
    "                            data.write(str(best_valid_logs))\n",
    "                        break\n",
    "            if i == 60:\n",
    "                with open(outDIR + 'best_model_' + '_'.join(suffix_list) + '_validation.txt','w') as data: \n",
    "                            data.write(str(best_valid_logs))\n",
    "                        \n",
    "            if i%15 == 0:\n",
    "                no_improve = 0\n",
    "                optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] * 0.1\n",
    "                print('Decrease decoder learning rate by factor of 10')\n",
    "\n",
    "        del model, train_epoch, valid_epoch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7ad66-30bc-479d-88df-0b2a8c283871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All processing complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d4f559-426c-4370-97f4-73ec59eb21ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_seg_env",
   "language": "python",
   "name": "py_seg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
